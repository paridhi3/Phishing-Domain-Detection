{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing Domain Detection\n",
    "## Experiment with Recursive Feature Elimination (RFE) as explained [here](https://www.sciencedirect.com/science/article/abs/pii/S1389128622004418?via%3Dihub)\n",
    "\n",
    "[Dataset Link](https://data.mendeley.com/datasets/72ptz43s9v/1)<br>\n",
    "[Dataset Description](https://www.sciencedirect.com/science/article/pii/S2352340920313202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/78_features.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_domain</th>\n",
       "      <th>qty_hyphen_domain</th>\n",
       "      <th>qty_vowels_domain</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_in_ip</th>\n",
       "      <th>server_client_domain</th>\n",
       "      <th>qty_dot_directory</th>\n",
       "      <th>qty_hyphen_directory</th>\n",
       "      <th>qty_underline_directory</th>\n",
       "      <th>qty_slash_directory</th>\n",
       "      <th>...</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_domain  qty_hyphen_domain  qty_vowels_domain  domain_length  \\\n",
       "0               2                  0                  4             17   \n",
       "1               2                  0                  5             16   \n",
       "2               2                  0                  3             14   \n",
       "3               2                  0                  7             19   \n",
       "4               2                  0                  5             19   \n",
       "\n",
       "   domain_in_ip  server_client_domain  qty_dot_directory  \\\n",
       "0             0                     0                  1   \n",
       "1             0                     0                  3   \n",
       "2             0                     0                  0   \n",
       "3             0                     0                  2   \n",
       "4             0                     0                 -1   \n",
       "\n",
       "   qty_hyphen_directory  qty_underline_directory  qty_slash_directory  ...  \\\n",
       "0                     0                        0                    1  ...   \n",
       "1                     0                        0                    3  ...   \n",
       "2                     0                        0                    1  ...   \n",
       "3                     0                        2                    5  ...   \n",
       "4                    -1                       -1                   -1  ...   \n",
       "\n",
       "   time_domain_expiration  qty_ip_resolved  qty_nameservers  qty_mx_servers  \\\n",
       "0                      -1                1                2               0   \n",
       "1                     150                1                2               1   \n",
       "2                      -1                1                2               3   \n",
       "3                      -1                1                2               0   \n",
       "4                     306                1                2               1   \n",
       "\n",
       "   ttl_hostname  tls_ssl_certificate  qty_redirects  url_google_index  \\\n",
       "0           892                    0              0                 0   \n",
       "1          9540                    1              0                 0   \n",
       "2           589                    1              0                 0   \n",
       "3           292                    1              0                 0   \n",
       "4          3597                    0              1                 0   \n",
       "\n",
       "   domain_google_index  url_shortened  \n",
       "0                    0              0  \n",
       "1                    0              0  \n",
       "2                    0              0  \n",
       "3                    0              0  \n",
       "4                    0              0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['phishing'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "87204    0\n",
       "87205    0\n",
       "87206    1\n",
       "87207    1\n",
       "87208    0\n",
       "Name: phishing, Length: 87203, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['phishing']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (87203, 77)\n",
      "Size of y: (87203,)\n"
     ]
    }
   ],
   "source": [
    "# checking the sizes of the sample data\n",
    "print(\"Size of X:\", X.shape)\n",
    "print(\"Size of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qty_dot_domain',\n",
       " 'qty_hyphen_domain',\n",
       " 'qty_vowels_domain',\n",
       " 'domain_length',\n",
       " 'domain_in_ip',\n",
       " 'server_client_domain',\n",
       " 'qty_dot_directory',\n",
       " 'qty_hyphen_directory',\n",
       " 'qty_underline_directory',\n",
       " 'qty_slash_directory',\n",
       " 'qty_questionmark_directory',\n",
       " 'qty_equal_directory',\n",
       " 'qty_at_directory',\n",
       " 'qty_and_directory',\n",
       " 'qty_exclamation_directory',\n",
       " 'qty_space_directory',\n",
       " 'qty_tilde_directory',\n",
       " 'qty_comma_directory',\n",
       " 'qty_plus_directory',\n",
       " 'qty_asterisk_directory',\n",
       " 'qty_hashtag_directory',\n",
       " 'qty_dollar_directory',\n",
       " 'qty_percent_directory',\n",
       " 'directory_length',\n",
       " 'qty_dot_file',\n",
       " 'qty_hyphen_file',\n",
       " 'qty_underline_file',\n",
       " 'qty_slash_file',\n",
       " 'qty_questionmark_file',\n",
       " 'qty_equal_file',\n",
       " 'qty_at_file',\n",
       " 'qty_and_file',\n",
       " 'qty_exclamation_file',\n",
       " 'qty_space_file',\n",
       " 'qty_tilde_file',\n",
       " 'qty_comma_file',\n",
       " 'qty_plus_file',\n",
       " 'qty_asterisk_file',\n",
       " 'qty_hashtag_file',\n",
       " 'qty_dollar_file',\n",
       " 'qty_percent_file',\n",
       " 'file_length',\n",
       " 'qty_dot_params',\n",
       " 'qty_hyphen_params',\n",
       " 'qty_underline_params',\n",
       " 'qty_slash_params',\n",
       " 'qty_questionmark_params',\n",
       " 'qty_equal_params',\n",
       " 'qty_at_params',\n",
       " 'qty_and_params',\n",
       " 'qty_exclamation_params',\n",
       " 'qty_space_params',\n",
       " 'qty_tilde_params',\n",
       " 'qty_comma_params',\n",
       " 'qty_plus_params',\n",
       " 'qty_asterisk_params',\n",
       " 'qty_hashtag_params',\n",
       " 'qty_dollar_params',\n",
       " 'qty_percent_params',\n",
       " 'params_length',\n",
       " 'tld_present_params',\n",
       " 'qty_params',\n",
       " 'email_in_url',\n",
       " 'time_response',\n",
       " 'domain_spf',\n",
       " 'asn_ip',\n",
       " 'time_domain_activation',\n",
       " 'time_domain_expiration',\n",
       " 'qty_ip_resolved',\n",
       " 'qty_nameservers',\n",
       " 'qty_mx_servers',\n",
       " 'ttl_hostname',\n",
       " 'tls_ssl_certificate',\n",
       " 'qty_redirects',\n",
       " 'url_google_index',\n",
       " 'domain_google_index',\n",
       " 'url_shortened']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols = X.columns.tolist()\n",
    "X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87203, 77)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69762, 77), (17441, 77), (69762,), (17441,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(scaler, open('scaling.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted, average='weighted')\n",
    "    recall = recall_score(true, predicted, average='weighted')\n",
    "    f1 = f1_score(true, predicted, average='weighted')\n",
    "    class_report = classification_report(predicted , true, target_names=[\"legitimate\",\"malicious\"])\n",
    "    return accuracy, precision, recall, f1, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "--------------------\n",
      "Train Accuracy: 0.999971331097159\n",
      "Train Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       1.00      1.00      1.00     45228\n",
      "   malicious       1.00      1.00      1.00     24534\n",
      "\n",
      "    accuracy                           1.00     69762\n",
      "   macro avg       1.00      1.00      1.00     69762\n",
      "weighted avg       1.00      1.00      1.00     69762\n",
      "\n",
      "-----------------------------------\n",
      "Test Accuracy: 0.9709879020698354\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.98      0.98      0.98     11434\n",
      "   malicious       0.96      0.95      0.96      6007\n",
      "\n",
      "    accuracy                           0.97     17441\n",
      "   macro avg       0.97      0.97      0.97     17441\n",
      "weighted avg       0.97      0.97      0.97     17441\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(random_state=42)\n",
    "    # \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42),\n",
    "    # \"XGBClassifier\": XGBClassifier(random_state=42),\n",
    "    # \"CatBoost Classifier\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "    # \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "train_accuracies = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "train_f1_scores = []\n",
    "test_accuracies = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "test_f1_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train dataset\n",
    "    model_train_accuracy, model_train_precision, model_train_recall, model_train_f1, model_classification_report_train = evaluate_model(y_train, y_train_pred)\n",
    "    # Evaluate Test dataset\n",
    "    model_test_accuracy, model_test_precision, model_test_recall, model_test_f1, model_classification_report_test = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(name)\n",
    "    print('-' * 20)\n",
    "    print('Train Accuracy:', model_train_accuracy)\n",
    "    print('Train Classification Report:\\n', model_classification_report_train)\n",
    "    print('-' * 35)\n",
    "    print('Test Accuracy:', model_test_accuracy)\n",
    "    print('Test Classification Report:\\n', model_classification_report_test)\n",
    "    print('=' * 35)\n",
    "    print('\\n')\n",
    "    \n",
    "    model_list.append(name)\n",
    "\n",
    "    train_accuracies.append(model_train_accuracy)\n",
    "    train_precisions.append(model_train_precision)\n",
    "    train_recalls.append(model_train_recall)\n",
    "    train_f1_scores.append(model_train_f1)\n",
    "    \n",
    "    test_accuracies.append(model_test_accuracy)\n",
    "    test_precisions.append(model_test_precision)\n",
    "    test_recalls.append(model_test_recall)\n",
    "    test_f1_scores.append(model_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(list(zip(model_list, test_accuracies)), columns=['Model Name', 'Test Accuracy']).sort_values(by=[\"Test Accuracy\"],ascending=False)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.970988</td>\n",
       "      <td>0.971056</td>\n",
       "      <td>0.970988</td>\n",
       "      <td>0.971015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  Test Accuracy  Test Precision  Test Recall  \\\n",
       "0  Random Forest Classifier       0.970988        0.971056     0.970988   \n",
       "\n",
       "   Test F1-score  \n",
       "0       0.971015  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model Name': model_list,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Test Precision': test_precisions,\n",
    "    'Test Recall': test_recalls,\n",
    "    'Test F1-score': test_f1_scores\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name        Random Forest Classifier\n",
       "Test Accuracy                     0.970988\n",
       "Test Precision                    0.971056\n",
       "Test Recall                       0.970988\n",
       "Test F1-score                     0.971015\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df['Test Accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name        Random Forest Classifier\n",
       "Test Accuracy                     0.970988\n",
       "Test Precision                    0.971056\n",
       "Test Recall                       0.970988\n",
       "Test F1-score                     0.971015\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df['Test Precision'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name        Random Forest Classifier\n",
       "Test Accuracy                     0.970988\n",
       "Test Precision                    0.971056\n",
       "Test Recall                       0.970988\n",
       "Test F1-score                     0.971015\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df['Test Recall'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name        Random Forest Classifier\n",
       "Test Accuracy                     0.970988\n",
       "Test Precision                    0.971056\n",
       "Test Recall                       0.970988\n",
       "Test F1-score                     0.971015\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df['Test F1-score'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is Random Forest Classifier with a Test F1-score of 0.9710145362863138\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "best_model_name = results_df.loc[results_df['Test F1-score'].idxmax()]['Model Name']\n",
    "best_model = models[best_model_name]\n",
    "# pickle.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "print(f\"The best model is {best_model_name} with a Test F1-score of {results_df.iloc[0]['Test F1-score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def recursive_feature_elimination(X_train=X_train, y_train=y_train, n_features_to_select=14, estimator=RandomForestClassifier()):\n",
    "\n",
    "    rfe = RFE(estimator=estimator, n_features_to_select=n_features_to_select)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    \n",
    "    selected_features = [X_cols[i] for i in range(len(X_cols)) if rfe.support_[i]]\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = recursive_feature_elimination()\n",
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['domain_length',\n",
    " 'qty_hyphen_directory',\n",
    " 'qty_slash_directory',\n",
    " 'directory_length',\n",
    " 'qty_dot_file',\n",
    " 'qty_exclamation_file',\n",
    " 'qty_space_file',\n",
    " 'qty_tilde_file',\n",
    " 'qty_percent_file',\n",
    " 'file_length',\n",
    " 'time_response',\n",
    " 'asn_ip',\n",
    " 'time_domain_activation',\n",
    " 'ttl_hostname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features2 = [\n",
    "#     \"qty_dot_domain\",\n",
    "#     \"qty_vowels_domain\",\n",
    "#     \"domain_length\",\n",
    "#     \"qty_dot_directory\",\n",
    "#     \"qty_slash_directory\",\n",
    "#     \"directory_length\",\n",
    "#     \"qty_dot_file\",\n",
    "#     \"file_length\",\n",
    "#     \"params_length\",\n",
    "#     \"time_response\",\n",
    "#     \"asn_ip\",\n",
    "#     \"time_domain_activation\",\n",
    "#     \"time_domain_expiration\",\n",
    "#     \"ttl_hostname\"\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Assuming 'importances', 'indices', and 'df' are already defined\n",
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted, average='weighted')\n",
    "    recall = recall_score(true, predicted, average='weighted')\n",
    "    f1 = f1_score(true, predicted, average='weighted')\n",
    "    class_report = classification_report(predicted, true, target_names=[\"legitimate\", \"malicious\"])\n",
    "    return accuracy, precision, recall, f1, class_report\n",
    "\n",
    "# Initialize lists to store results\n",
    "j_values = []\n",
    "num_features = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over the range of j\n",
    "for j in [x * 0.001 for x in range(0, 101)]:\n",
    "    important_features = []\n",
    "    for i in indices:\n",
    "        if importances[i] >= j:\n",
    "            important_features.append(df.columns[i])\n",
    "    \n",
    "    # Store the number of important features\n",
    "    num_features.append(len(important_features))\n",
    "    \n",
    "    # Check if there are features selected\n",
    "    if len(important_features) == 0:\n",
    "        f1_scores.append(np.nan)  # Handle case where no features are selected\n",
    "        continue\n",
    "\n",
    "    # Prepare the data\n",
    "    X = df[important_features]\n",
    "    y = df['phishing']\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define and train the model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    _, _, _, f1, _ = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    # Store the F1-score\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Store the current j value\n",
    "    j_values.append(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
